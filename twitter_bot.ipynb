{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = open('auth.txt','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = auth[0][:-1]\n",
    "access_token_secret = auth[1][:-1]\n",
    "consumer_key = auth[2][:-1]\n",
    "consumer_secret = auth[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_names = open('usernames.txt','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    all_tweets = []\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name, count=200)\n",
    "    all_tweets.extend(new_tweets)\n",
    "    last_tweet = all_tweets[-1].id-1\n",
    "    while len(new_tweets)>0:\n",
    "        new_tweets = api.user_timeline(screen_name,count=200,max_id=last_tweet)\n",
    "        all_tweets.extend(new_tweets)\n",
    "        last_tweet = all_tweets[-1].id-1\n",
    "    returndf = pd.DataFrame()\n",
    "    returndf['text'] = [str(tweet.text.encode(\"utf-8\"))[1:] for tweet in all_tweets]\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chris = get_all_tweets(user_names[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanup_token2(token):\n",
    "    token = token.strip('\\'')\n",
    "    token = token.strip('(')\n",
    "    token = token.strip(')')\n",
    "    token = token.strip('\\\"')\n",
    "    token = token.strip(':')\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_token(token):\n",
    "    if len(token)<1:\n",
    "        return False\n",
    "    if token[0]==\"@\":\n",
    "        return False\n",
    "    if token.lower()[0:2]==\"rt\":\n",
    "        return False\n",
    "    if token[0]==\"#\":\n",
    "        return False\n",
    "    if 'http' in token:\n",
    "        return False\n",
    "    if '\\\\' in token:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "natalie = get_all_tweets(user_names[1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shinra = get_all_tweets(user_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_bottom(x):\n",
    "    if x>-1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_top(x,n):\n",
    "    if x>n-2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_freq_table(df,n):\n",
    "    freq_table = {}\n",
    "    freq_table['$size$']=n\n",
    "    for i in range(len(df)):\n",
    "        tweet = df['text'].iloc[i]\n",
    "        token_list = str(tweet).split(' ')\n",
    "        for j in range(len(token_list)):\n",
    "            token_list[j] = cleanup_token2(token_list[j])\n",
    "        token_list = [x for x in token_list if check_token(x)]\n",
    "        token_list.append('$end$')\n",
    "        token_list.insert(0,'$beg$')\n",
    "        for i in range(len(token_list)):\n",
    "            if len(token_list)>2*n:\n",
    "                if not check_bottom(i-n):\n",
    "                    new_key = token_list[:i+1]\n",
    "                    new_value = token_list[i+1]\n",
    "                elif check_top(len(token_list)-i,n):\n",
    "                    new_key = token_list[i-2:i-2+n]\n",
    "                    new_value = token_list[i+n-2]\n",
    "                new_key = tuple(new_key)\n",
    "                if new_key not in freq_table:\n",
    "                    freq_table[new_key]=[new_value]\n",
    "                else:\n",
    "                    freq_table[new_key].append(new_value)\n",
    "        if n==1:\n",
    "            new_key = tuple([token_list[-2]])\n",
    "            new_value = token_list[-1]\n",
    "            if new_key not in freq_table:\n",
    "                freq_table[new_key]=[new_value]\n",
    "            else:\n",
    "                freq_table[new_key].append(new_value)\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tweet(freq_table):\n",
    "    n = freq_table['$size$']\n",
    "    tweet_string = ''\n",
    "    tweet_token = ['$beg$']\n",
    "    count = 0\n",
    "    while tweet_token[-1]!='$end$' or count>50:\n",
    "        if tweet_token[-1]=='$end$':\n",
    "            break\n",
    "        tweet_token.append(random.choice(freq_table[tuple(tweet_token)]))\n",
    "        if len(tweet_token)>n:\n",
    "            tweet_token.pop(0)\n",
    "        if tweet_token[-1]!='$end$':\n",
    "            tweet_string += tweet_token[-1] + ' '\n",
    "        count +=1\n",
    "    return(tweet_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tweets with n-gram of 1\n",
      "11-14-12 today real scientist would be happy ending after watching the first time someone puts out to more exciting than most people in the Mumford & the last century \n",
      "all the friendly machines that sephora foundation tryna see him he had this $100 \n",
      "Marriage is real life, I'd do to pass out. \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 2\n",
      "uhh you were born. Must really bother \n",
      "I really care. \n",
      "Give me leaks \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 3\n",
      "science agrees with my prejudice unless it in which case it Real Science \n",
      "A White supremacist murdered her husband, administration stays silent, &amp; now She faces the \n",
      "If I eat Mac &amp; Cheese from Whole Foods does it count as a vegetable? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Generating tweets with n-gram of \" + str(i+1))\n",
    "    df = get_freq_table(chris,i+1)\n",
    "    for j in range(3):\n",
    "        print(generate_tweet(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tweets with n-gram of 1\n",
      "a nice, relaxing day of billionaires is Top 10 lives in my kids watching riverdale at 22 or \n",
      "if the hounds \n",
      "white supremacy even good morning \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 2\n",
      "like it's a print of the humanities telling Silicon Valley tech giants about how much soup i bought, which means it's time to fake my own death. \n",
      "if you \n",
      "i can't remember if i'm awake because i'm excited to see how my life is to take away millions of people's \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 3\n",
      "wait wait what is this app \n",
      "please pray for me ya'll my right ear hasn't popped in three days and if it doesn't get it's act together this \n",
      "If my boyfriend doesn't try to conjure me up from the dead then he was never my boyfriend \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Generating tweets with n-gram of \" + str(i+1))\n",
    "    df = get_freq_table(natalie,i+1)\n",
    "    for j in range(3):\n",
    "        print(generate_tweet(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tweets with n-gram of 1\n",
      "yeah same session \n",
      "please bring me \n",
      "black cat encountered lately. an Oil magnate, after the album of them ever and they going to no way of all day to cayde-6 and sky fell asleep and bill throw at 3:30pm \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 2\n",
      "ICON a cute holiday icon? you've come to the results of this Stink Semester and then share the link to a psn group so our raid group is just to let you know that if you're reading this, sit up straight \n",
      "there's benefits to both!! client-based work is picky bc sometimes we talk about morality in turf war \n",
      "it's so incredible and xemnas + ansem were doing what they do best speaking \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 3\n",
      "today in d&amp;d we confused basilisks with baskets and befriended a nice yuan-ti \n",
      "put chain chomp in smash send tweet \n",
      "the good news snowing, snow is pretty and might cancel bad news i want the mailmen to be \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Generating tweets with n-gram of \" + str(i+1))\n",
    "    df = get_freq_table(shinra,i+1)\n",
    "    for j in range(3):\n",
    "        print(generate_tweet(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaden = get_all_tweets('officialjaden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tweets with n-gram of 1\n",
      "Looking To Sew This Partnership \n",
      "CLEMENTINE Records ||| \n",
      "August 25th! You On My Moms Out Of Me in places I Need To Everyone That Ten Ten going \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 2\n",
      "SYRE Died In The Basas, And I Isn't Patient. || \n",
      "Rich the kid FT x Like this \n",
      "The Episode is now available on streaming services \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 3\n",
      "We Could Be Never Endless -Syre \n",
      "How Do We Feel About \n",
      "NUMBER 5 I'm Freaking Out Thank You Soo Much I Love You Guys Thank You \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Generating tweets with n-gram of \" + str(i+1))\n",
    "    df = get_freq_table(jaden,i+1)\n",
    "    for j in range(3):\n",
    "        print(generate_tweet(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald = get_all_tweets('POTUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tweets with n-gram of 1\n",
      "We have a \n",
      "So looking good \n",
      "You may be, coming to save hundreds of historic economic miracle by the White House overwhelmingly passes bipartisan meeting today at the International so \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 2\n",
      "A closer look at the celebrating the Lunar New Year. Today, people across Guatemala affected by substance abuse, and President Duda agreed to buy our friends with bad Trade Deals ever made. The word is that I was limiting the FBI lovers, Peter Strzok and Lisa Page are getting \n",
      "As I promised, today the blast furnace here in Granite City is blazing \n",
      "I hope the discovery and eventual recovery of the bravest people on Yom Kippur, the holiest day \n",
      "\n",
      "\n",
      "Generating tweets with n-gram of 3\n",
      "Last week, Vice President Pence are traveling to Florida and Georiga today. tour damage from \n",
      "...we have six of the biggest benefits from President tax cuts. \n",
      "Moments ago, President Trump signed a new trade agreement with Mexico and Canada, will be hosting the 2026 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Generating tweets with n-gram of \" + str(i+1))\n",
    "    df = get_freq_table(donald,i+1)\n",
    "    for j in range(3):\n",
    "        print(generate_tweet(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
